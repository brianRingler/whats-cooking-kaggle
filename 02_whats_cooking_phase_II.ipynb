{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# What's Cooking? Phase II\n",
    "***\n",
    "\n",
    "Here we are staring Phase II which will build on Phase I and we will start building some models. We will be keeping the models hight level and will focus on establishing some quick baselines and see if it is possible to eliminate any classifiers from additional parameter tuning in the next phase of the process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Index\n",
    "***\n",
    "\n",
    "* [**Imports**](#import)\n",
    "* [**Custom Functions**](#cust)\n",
    "* [**Data Import**](#read)\n",
    "* [**Model Evaluation**](#model)\n",
    "* [**Summary**](#sum)\n",
    "* [**Next Steps**](#next)\n",
    "\n",
    "<a id=\"---\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import\"></a>\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cust\"></a>\n",
    "# Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# create new features function \n",
    "def new_features(df_name):\n",
    "    '''Create 4 new features for given dataframe'''\n",
    "    # create feature 1 avg ingredient length\n",
    "    num_ingred = 0\n",
    "    avg_length =[]\n",
    "    for i in df_name.itertuples():\n",
    "        ing_length = 0\n",
    "        num_ingred = len(i.ingredients)\n",
    "        # get the length each ingredient\n",
    "        for ing in i.ingredients:\n",
    "            ing_length += len(ing)\n",
    "        avg_length.append(round(ing_length / num_ingred,2))\n",
    "    df_name['avg_ingredients_len'] = avg_length  \n",
    "    # create feature 2 count of ingredients \n",
    "    df_name['num_ingredients'] = df_name['ingredients'].apply(len)\n",
    "    # create feature 3 avg ingredient length\n",
    "    df_name['difference'] = df_name['avg_ingredients_len'] - df_name['num_ingredients']\n",
    "    # create feature 4 convert ingredients from list to string \n",
    "    df_name['ingredients_str'] = df_name['ingredients'].astype('str')\n",
    "    return df_name\n",
    "\n",
    "\n",
    "def hist_bins(d_frame, col_name, \n",
    "               title=\"\",y_axis=\"\",x_axis=\"\",adder = 0, start = 0, stop = 0):\n",
    "    '''Create a histogram with adjusted bins'''\n",
    "    bin_edges = np.arange(start, stop + adder, adder)\n",
    "\n",
    "    plt.axvline(d_frame[col_name].median(),color='y',linestyle='--',lw=2,label='Median')\n",
    "    plt.axvline(d_frame[col_name].mean(),color='r',linestyle='--',lw=2,label='Mean')\n",
    "    \n",
    "    plt.title(title,fontsize=14)\n",
    "    plt.ylabel(y_axis,fontsize=14)\n",
    "    plt.xlabel(x_axis,fontsize=14)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.legend(fontsize=14)\n",
    "    return plt.hist(d_frame[col_name], bins = bin_edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read\"></a>\n",
    "# Data Import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the custom function from Phase I we will import the two datasets which will have our new features:\n",
    "\n",
    "* **avg_ingredients_lens**: For each observation average the length those ingredients \n",
    "* **num_ingredients**: For each observation provide the count of ingredients \n",
    "* **difference**: is...`avg_ingredienta_len` - `num_ingredients`\n",
    "* **ingredients_str**: ingredients converted to a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_features(pd.read_json('whats_cooking_train.json'))\n",
    "new = new_features(pd.read_json('whats_cooking_test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>avg_ingredients_len</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>difference</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>9</td>\n",
       "      <td>3.00</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>10.09</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>10.33</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.67</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>6.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>10.10</td>\n",
       "      <td>20</td>\n",
       "      <td>-9.90</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   avg_ingredients_len  num_ingredients  difference  \\\n",
       "0                12.00                9        3.00   \n",
       "1                10.09               11       -0.91   \n",
       "2                10.33               12       -1.67   \n",
       "3                 6.75                4        2.75   \n",
       "4                10.10               20       -9.90   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>avg_ingredients_len</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>difference</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39769</th>\n",
       "      <td>29109</td>\n",
       "      <td>irish</td>\n",
       "      <td>[light brown sugar, granulated sugar, butter, ...</td>\n",
       "      <td>12.17</td>\n",
       "      <td>12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>['light brown sugar', 'granulated sugar', 'but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39770</th>\n",
       "      <td>11462</td>\n",
       "      <td>italian</td>\n",
       "      <td>[KRAFT Zesty Italian Dressing, purple onion, b...</td>\n",
       "      <td>17.00</td>\n",
       "      <td>7</td>\n",
       "      <td>10.00</td>\n",
       "      <td>['KRAFT Zesty Italian Dressing', 'purple onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39771</th>\n",
       "      <td>2238</td>\n",
       "      <td>irish</td>\n",
       "      <td>[eggs, citrus fruit, raisins, sourdough starte...</td>\n",
       "      <td>8.25</td>\n",
       "      <td>12</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>['eggs', 'citrus fruit', 'raisins', 'sourdough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39772</th>\n",
       "      <td>41882</td>\n",
       "      <td>chinese</td>\n",
       "      <td>[boneless chicken skinless thigh, minced garli...</td>\n",
       "      <td>13.14</td>\n",
       "      <td>21</td>\n",
       "      <td>-7.86</td>\n",
       "      <td>['boneless chicken skinless thigh', 'minced ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39773</th>\n",
       "      <td>2362</td>\n",
       "      <td>mexican</td>\n",
       "      <td>[green chile, jalapeno chilies, onions, ground...</td>\n",
       "      <td>12.00</td>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['green chile', 'jalapeno chilies', 'onions', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  cuisine                                        ingredients  \\\n",
       "39769  29109    irish  [light brown sugar, granulated sugar, butter, ...   \n",
       "39770  11462  italian  [KRAFT Zesty Italian Dressing, purple onion, b...   \n",
       "39771   2238    irish  [eggs, citrus fruit, raisins, sourdough starte...   \n",
       "39772  41882  chinese  [boneless chicken skinless thigh, minced garli...   \n",
       "39773   2362  mexican  [green chile, jalapeno chilies, onions, ground...   \n",
       "\n",
       "       avg_ingredients_len  num_ingredients  difference  \\\n",
       "39769                12.17               12        0.17   \n",
       "39770                17.00                7       10.00   \n",
       "39771                 8.25               12       -3.75   \n",
       "39772                13.14               21       -7.86   \n",
       "39773                12.00               12        0.00   \n",
       "\n",
       "                                         ingredients_str  \n",
       "39769  ['light brown sugar', 'granulated sugar', 'but...  \n",
       "39770  ['KRAFT Zesty Italian Dressing', 'purple onion...  \n",
       "39771  ['eggs', 'citrus fruit', 'raisins', 'sourdough...  \n",
       "39772  ['boneless chicken skinless thigh', 'minced ga...  \n",
       "39773  ['green chile', 'jalapeno chilies', 'onions', ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is 39,774 observations with 7 features. The testing data is 9,944 by 6. It does not contain the features 'cuisine' which is the variable we want to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Data:\t (39774, 7)\n",
      "Shape of Testing Data:\t (9944, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training Data:\\t {df.shape}\")\n",
    "print(f\"Shape of Testing Data:\\t {new.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are not missing any values and the data types for each feature should be fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Accuracy/DummyClassifier\n",
    "Here we are going to use sklearns DummyClassifier to provide the scores using a couple different strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create four variables for the different feature options and our predictor value y.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features \n",
    "features1 = ['ingredients_str']\n",
    "features2 = ['avg_ingredients_len','num_ingredients']\n",
    "features3 = ['difference']\n",
    "features4 = ['avg_ingredients_len','num_ingredients','difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier Most Frequent Score: 0.1961\n"
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features2], df['cuisine'], random_state=42)\n",
    "\n",
    "# create most frequent dummyclassifier\n",
    "dumb_mf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# create dummy classifier\n",
    "dumb_mf.fit(X_train,y_train)\n",
    "# create y pred values\n",
    "y_pred_mf = dumb_mf.predict(X_test)\n",
    "\n",
    "# run accuracy score\n",
    "score_mf = metrics.accuracy_score(y_test,y_pred_mf)\n",
    "print(f\"DummyClassifier Most Frequent Score: {round(score_mf,4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have confirmed that by selecting Italian for all cuisines our model will be correct **19.61** percent of the time.  We will now start crating a simple baseline strategy for multiple models. We will first instantiate our classifiers for the models we want to try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifiers \n",
    "vect = CountVectorizer() # token_pattern=r\"'([a-z ]+)'\"\n",
    "svm_cl = svm.SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "nb = MultinomialNB()\n",
    "log = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we tried `Support Vector Machines`, `K-Neighbors` and `Multinominal Naive Bayes` on two of the features we engineered. The best score was 0.2222 which is only slightly higher than our `most frequent` baseline of 0.1961. \n",
    "\n",
    "Note: SVM takes the longest to run. If this is a model used during parameter tuning maybe switch to Train, Test Split? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y \n",
    "X = df[features2]\n",
    "y = df['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM High Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22220545319749468"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(svm_cl, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13936245605822417"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MN Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2119977203932037"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(nb, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredients Only \n",
    "Here we are going to focus on using `CountVectorizer` to create a document term matrix of the ingredients only. We converted the the list of ingredients to a string and now we will convert to a Document Term Matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y \n",
    "\n",
    "# ingredients as a string \n",
    "X = df['ingredients_str'] # NOTE must be 1d np array or panda series\n",
    "y = df['cuisine']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** When creating `X` for the DTM it must a 1d numpy array or pandas series. **`df[features1]`** returns a pandas core Dataframe which will not work with CountVectorizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Pipeline** for Proper Cross-val:\n",
    "* Create a pipeline for `vect` and each classifier. We want to do this so when we use cross validation we want each of the 5 folds to introduce the data for the first time. \n",
    "\n",
    "**`CountVect`** has `all default settings` as do the individual classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# countVect and nb\n",
    "pipe_nb = make_pipeline(vect, nb)\n",
    "# countVect and knn\n",
    "pipe_knn = make_pipeline(vect, knn)\n",
    "# countVect and svm_cl\n",
    "pipe_svm_cl = make_pipeline(vect, svm_cl)\n",
    "# countVect and logistic regression\n",
    "pipe_log = make_pipeline(vect, log)\n",
    "# countVect and random forest\n",
    "pipe_rf = make_pipeline(vect, rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN** with CountVect all defaults scored **0.6361**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6360688888829185"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect and knn all defaults\n",
    "cross_val_score(pipe_knn, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MN Naive Bayes** with CountVect all defaults scored **0.7235**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723487776272334"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect and nb all defaults\n",
    "cross_val_score(pipe_nb, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** with CounVect all defaults scored **0.7834**\n",
    "* Note, `max_iter` was increased from default of 100 to 1000 to allow for algorithm to converge. The document term matrix is over 6,000 words which requires larger width before converging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.783376239271474"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect and log reg all defaults (max_iter=1000)\n",
    "cross_val_score(pipe_log, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** with CountVect all defaults scored **0.7562**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7562730198958277"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect and random forest all defaults\n",
    "cross_val_score(pipe_rf, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machines** with CountVect all defaults scored **0.7772**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7772164205653279"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vect and svm_cl all defaults\n",
    "cross_val_score(pipe_svm_cl, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sum\"></a>\n",
    "# Summary Baseline Models \n",
    "We wanted to establish some early baselines for a few different classifiers. As well, take a look at how using just the ingredients with our engineered features faired. \n",
    "\n",
    "**Null Accuracy**\n",
    "Our first baseline was to establish what would happen if we built a most-frequent model. We found that we would be correct **19.61 percent** of the time. That value seems low and we should be able to improve on that but its a quick baseline and will actually help us.\n",
    "\n",
    "**Engineered Features**\n",
    "We want to test out our engineered features.  For that we used three classifiers and two of the features. Average ingredient length and number of ingredients. We used k-fold cross-validation and received the following scores:\n",
    "* SVM - Had the high score at 0.222\n",
    "* KNN - Scored 0.1393\n",
    "* MN Naive Bayes- Scored 0.212\n",
    "\n",
    "KNN was actually worse than the null model and the other two scores only slightly higher. These features alone are not enough. We can try creating a model that combines the engineered features with list of ingredients.\n",
    "\n",
    "**Ingredients Only**\n",
    "Final baseline we tested models using CountVectorizer to create a DTM on the list of ingredients. We introduced two classifiers because we noticed higher scores.  Everything had default settings with the exception of logistic regression. Again, we used cross validation and set k equal to 5. We tested at 10 and received a similar score so we will remain with 5.\n",
    "* KNN Scored 0.6360\n",
    "* NB Scored 0.72\n",
    "* Log Reg Scored 0.78\n",
    "* Random Forest Scored 0.76\n",
    "* SVM Scored 0.78\n",
    "\n",
    "With the exception of KNN all of the models scored in the the 70's. At this point it we will need to continue with all of the models as it is not clear which will perform the best.  While KNN is the lowest it is not uncommon to see a large increase just by adjusting the number of neighbors. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"next\"></a>\n",
    "# Next Steps \n",
    "Now we will move on to tuning individual model parameters. We will look at single model tuning and even multiple model tuning. Recall we have parameters that we can tune within CountVectorizer and the classifier.  For this we will utilize pipelines and grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
